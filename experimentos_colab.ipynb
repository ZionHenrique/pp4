{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimentos de Deep Learning com `nutrition.csv` e Food-101\n",
        "\n",
        "Este notebook reúne dois experimentos completos e prontos para rodar no Google Colab:\n",
        "\n",
        "1. **Regressão tabular** usando o arquivo `nutrition.csv` para prever calorias com uma rede totalmente conectada.\n",
        "2. **Classificação de imagens** com o dataset Food-101 contido em `archive (1)` (subpasta `images/`) utilizando transferência de aprendizado.\n",
        "\n",
        "Cada bloco inclui comentários e parâmetros configuráveis para facilitar a adaptação ao seu ambiente local ou ao Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparando os dados no Google Colab\n",
        "\n",
        "1. Faça upload da pasta `archive (1)` (mantendo a estrutura `images/` e `meta/`) e do arquivo `nutrition.csv` para a pasta desejada no Google Drive. Sugestão: `MyDrive/pp4_datasets/`.\n",
        "2. No Colab, monte o Drive (`drive.mount('/content/drive')`) e aponte `BASE_DATA_DIR` para essa pasta.\n",
        "3. Ajuste os parâmetros `FOOD_IMAGES_DIR` e `NUTRITION_CSV_PATH` abaixo caso use outro caminho.\n",
        "\n",
        "> Dica: compacte `archive (1)` em `.zip` antes do upload e descompacte no Colab com `!unzip` para agilizar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Configurações globais\n",
        "# ------------------------------------------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount(\"/content/drive\")\n",
        "    BASE_DATA_DIR = Path(\"/content/drive/MyDrive/pp4_datasets\")\n",
        "else:\n",
        "    BASE_DATA_DIR = Path.cwd()\n",
        "\n",
        "FOOD_IMAGES_DIR = BASE_DATA_DIR / \"archive (1)\" / \"images\"\n",
        "NUTRITION_CSV_PATH = BASE_DATA_DIR / \"nutrition.csv\"\n",
        "MODEL_OUTPUT_DIR = BASE_DATA_DIR / \"modelos_treinados\"\n",
        "MODEL_OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Rodando no Colab? {IN_COLAB}\")\n",
        "print(f\"Base de dados: {BASE_DATA_DIR}\")\n",
        "print(f\"Imagens Food-101: {FOOD_IMAGES_DIR.exists()}\")\n",
        "print(f\"Tabela de nutrição: {NUTRITION_CSV_PATH.exists()}\")\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "print(f\"GPUs detectadas: {len(gpus)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if FOOD_IMAGES_DIR.exists():\n",
        "    classes = sorted([d.name for d in FOOD_IMAGES_DIR.iterdir() if d.is_dir()])\n",
        "    sample_counts = {c: len(list((FOOD_IMAGES_DIR / c).glob(\"*.jpg\"))) for c in classes[:5]}\n",
        "    print(f\"Total de classes detectadas: {len(classes)} (mostrando 5)\")\n",
        "    print(sample_counts)\n",
        "else:\n",
        "    print(\"⚠️ Pasta de imagens não localizada. Ajuste FOOD_IMAGES_DIR acima.\")\n",
        "\n",
        "if NUTRITION_CSV_PATH.exists():\n",
        "    preview = pd.read_csv(NUTRITION_CSV_PATH, nrows=5)\n",
        "    display(preview.head())\n",
        "else:\n",
        "    print(\"⚠️ Arquivo nutrition.csv não encontrado. Ajuste NUTRITION_CSV_PATH.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 1 — Regressão de calorias com `nutrition.csv`\n",
        "\n",
        "Objetivo: prever o valor calórico (kcal) com base nos demais nutrientes usando uma rede densa. Este processo inclui limpeza automática (remoção de unidades como `g`, `mg`, etc.), normalização e validação cruzada simples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_prepare_nutrition(csv_path: Path, drop_threshold: float = 0.4):\n",
        "    assert csv_path.exists(), f\"Arquivo {csv_path} não encontrado.\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # Remove colunas textuais que não contribuem para o modelo\n",
        "    text_cols = [\"name\", \"serving_size\"]\n",
        "    existing_text_cols = [c for c in text_cols if c in df.columns]\n",
        "    df = df.drop(columns=existing_text_cols)\n",
        "\n",
        "    def _to_numeric(series: pd.Series) -> pd.Series:\n",
        "        cleaned = series.astype(str).str.replace(r\"[^0-9eE\\.\\-]\", \"\", regex=True)\n",
        "        cleaned = cleaned.replace({\"\": np.nan, \"nan\": np.nan})\n",
        "        return pd.to_numeric(cleaned, errors=\"coerce\")\n",
        "\n",
        "    df = df.apply(_to_numeric)\n",
        "\n",
        "    # Descarta colunas com muitos NaNs\n",
        "    null_ratio = df.isna().mean()\n",
        "    cols_to_drop = null_ratio[null_ratio > drop_threshold].index.tolist()\n",
        "    df = df.drop(columns=cols_to_drop)\n",
        "\n",
        "    # Remove linhas quase vazias e preenche o restante com mediana\n",
        "    min_non_na = int(df.shape[1] * 0.6)\n",
        "    df = df.dropna(thresh=min_non_na)\n",
        "    df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "    target = \"calories\"\n",
        "    if target not in df.columns:\n",
        "        raise ValueError(\"Coluna 'calories' não encontrada após limpeza.\")\n",
        "\n",
        "    feature_df = df.drop(columns=[target])\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(feature_df)\n",
        "    targets = df[target].values.astype(np.float32)\n",
        "\n",
        "    feature_names = feature_df.columns.tolist()\n",
        "    return features, targets, feature_names, scaler\n",
        "\n",
        "X, y, nutrition_feature_names, nutrition_scaler = load_and_prepare_nutrition(NUTRITION_CSV_PATH)\n",
        "print(f\"Shape final: X={X.shape}, y={y.shape}, nº de features={len(nutrition_feature_names)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_size = 0.2\n",
        "batch_size = 64\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=SEED\n",
        ")\n",
        "\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "    .shuffle(buffer_size=len(X_train), seed=SEED)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "val_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "    .batch(batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "len_train = len(X_train)\n",
        "len_val = len(X_val)\n",
        "print(f\"Treino: {len_train} amostras | Validação: {len_val} amostras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_tabular_model(input_dim: int) -> keras.Model:\n",
        "    inputs = keras.Input(shape=(input_dim,), name=\"nutrition_features\")\n",
        "    x = layers.Dense(256, activation=\"relu\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(1, name=\"calories_output\")(x)\n",
        "    return keras.Model(inputs, outputs, name=\"nutrition_regressor\")\n",
        "\n",
        "nutrition_model = build_tabular_model(X.shape[1])\n",
        "nutrition_model.summary()\n",
        "\n",
        "nutrition_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"mse\",\n",
        "    metrics=[\n",
        "        keras.metrics.RootMeanSquaredError(name=\"rmse\"),\n",
        "        keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_rmse\", patience=10, restore_best_weights=True\n",
        ")\n",
        "plateau = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_rmse\", factor=0.5, patience=5, min_lr=1e-5\n",
        ")\n",
        "\n",
        "history = nutrition_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=100,\n",
        "    callbacks=[early_stop, plateau],\n",
        "    verbose=2,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "display(history_df.tail())\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "history_df[[\"rmse\", \"val_rmse\"]].plot(ax=axes[0])\n",
        "axes[0].set_title(\"RMSE vs Épocas\")\n",
        "axes[0].set_xlabel(\"épocas\")\n",
        "axes[0].set_ylabel(\"rmse\")\n",
        "axes[0].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "history_df[[\"mae\", \"val_mae\"]].plot(ax=axes[1])\n",
        "axes[1].set_title(\"MAE vs Épocas\")\n",
        "axes[1].set_xlabel(\"épocas\")\n",
        "axes[1].set_ylabel(\"mae\")\n",
        "axes[1].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Avaliação rápida do regressor\n",
        "\n",
        "O bloco abaixo calcula métricas no conjunto de validação, gera previsões de exemplo e salva o modelo/normalizador para reutilização no Colab ou em produção.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "val_preds = nutrition_model.predict(val_ds).squeeze()\n",
        "val_true = y_val\n",
        "rmse = tf.keras.metrics.RootMeanSquaredError()\n",
        "mae = tf.keras.metrics.MeanAbsoluteError()\n",
        "rmse.update_state(val_true, val_preds)\n",
        "mae.update_state(val_true, val_preds)\n",
        "print({\"rmse\": float(rmse.result()), \"mae\": float(mae.result())})\n",
        "print({\"r2\": r2_score(val_true, val_preds)})\n",
        "\n",
        "sample_idx = np.random.choice(len(X_val), size=5, replace=False)\n",
        "sample_features = X_val[sample_idx]\n",
        "sample_truth = y_val[sample_idx]\n",
        "sample_preds = nutrition_model.predict(sample_features).squeeze()\n",
        "\n",
        "comparison_df = pd.DataFrame(\n",
        "    {\n",
        "        \"calories_real\": sample_truth,\n",
        "        \"calories_previsto\": sample_preds,\n",
        "    }\n",
        ")\n",
        "display(comparison_df)\n",
        "\n",
        "regressor_path = MODEL_OUTPUT_DIR / \"nutrition_regressor.keras\"\n",
        "nutrition_model.save(regressor_path)\n",
        "\n",
        "scaler_path = MODEL_OUTPUT_DIR / \"nutrition_scaler.npy\"\n",
        "np.save(scaler_path, {\n",
        "    \"mean\": nutrition_scaler.mean_,\n",
        "    \"scale\": nutrition_scaler.scale_,\n",
        "    \"feature_names\": np.array(nutrition_feature_names),\n",
        "})\n",
        "\n",
        "print(f\"Modelo salvo em {regressor_path}\")\n",
        "print(f\"Scaler salvo em {scaler_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 2 — Classificação de imagens com Food-101\n",
        "\n",
        "Objetivo: treinar um classificador de 101 classes utilizando transferência de aprendizado (EfficientNetB0). Habilite GPU no Colab para tempos de treino aceitáveis. É possível limitar a fração de dados para prototipagem rápida ajustando `TRAIN_SPLIT_FRACTION`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "TRAIN_SPLIT_FRACTION = 0.2  # use <=1.0 para reduzir a quantidade de imagens de treino\n",
        "VAL_SPLIT = 0.1\n",
        "MAX_EPOCHS = 25\n",
        "LEARNING_RATE = 2e-4\n",
        "\n",
        "print({\n",
        "    \"IMG_SIZE\": IMG_SIZE,\n",
        "    \"BATCH_SIZE\": BATCH_SIZE,\n",
        "    \"TRAIN_SPLIT_FRACTION\": TRAIN_SPLIT_FRACTION,\n",
        "    \"VAL_SPLIT\": VAL_SPLIT,\n",
        "    \"MAX_EPOCHS\": MAX_EPOCHS,\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_food_datasets(\n",
        "    images_dir: Path,\n",
        "    image_size: tuple[int, int] = IMG_SIZE,\n",
        "    batch_size: int = BATCH_SIZE,\n",
        "    val_split: float = VAL_SPLIT,\n",
        "    subset_fraction: float = TRAIN_SPLIT_FRACTION,\n",
        "):\n",
        "    assert images_dir.exists(), f\"Pasta {images_dir} não encontrada.\"\n",
        "    assert 0.0 < val_split < 1.0, \"VAL_SPLIT deve estar entre 0 e 1\"\n",
        "    assert 0.0 < subset_fraction <= 1.0, \"TRAIN_SPLIT_FRACTION deve estar entre 0 e 1\"\n",
        "\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        images_dir,\n",
        "        validation_split=val_split,\n",
        "        subset=\"training\",\n",
        "        seed=SEED,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode=\"categorical\",\n",
        "    )\n",
        "\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        images_dir,\n",
        "        validation_split=val_split,\n",
        "        subset=\"validation\",\n",
        "        seed=SEED,\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        label_mode=\"categorical\",\n",
        "    )\n",
        "\n",
        "    if subset_fraction < 1.0:\n",
        "        train_batches = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "        keep_batches = max(1, int(train_batches * subset_fraction))\n",
        "        train_ds = train_ds.take(keep_batches)\n",
        "        print(f\"Subamostrando treino para {keep_batches} lotes\")\n",
        "\n",
        "    class_names = train_ds.class_names\n",
        "\n",
        "    def configure(ds: tf.data.Dataset, shuffle: bool = False) -> tf.data.Dataset:\n",
        "        if shuffle:\n",
        "            ds = ds.shuffle(1024, seed=SEED)\n",
        "        return ds.prefetch(AUTOTUNE)\n",
        "\n",
        "    return configure(train_ds, shuffle=True), configure(val_ds), class_names\n",
        "\n",
        "\n",
        "food_train_ds, food_val_ds, food_class_names = build_food_datasets(FOOD_IMAGES_DIR)\n",
        "num_classes = len(food_class_names)\n",
        "print(f\"Classes: {num_classes}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.05),\n",
        "        layers.RandomZoom(0.1),\n",
        "        layers.RandomContrast(0.1),\n",
        "    ],\n",
        "    name=\"augmentation_block\",\n",
        ")\n",
        "\n",
        "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_food_model(num_classes: int) -> keras.Model:\n",
        "    inputs = keras.Input(shape=(*IMG_SIZE, 3), name=\"food_image\")\n",
        "    x = data_augmentation(inputs)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    base_model = tf.keras.applications.EfficientNetB0(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_tensor=x,\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"food_logits\")(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs, name=\"food101_classifier\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "food_model = build_food_model(num_classes)\n",
        "food_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "food_ckpt_path = MODEL_OUTPUT_DIR / \"food101_classifier.keras\"\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=food_ckpt_path,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        verbose=1,\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "    ),\n",
        "]\n",
        "\n",
        "food_history = food_model.fit(\n",
        "    food_train_ds,\n",
        "    validation_data=food_val_ds,\n",
        "    epochs=MAX_EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "food_history_df = pd.DataFrame(food_history.history)\n",
        "display(food_history_df.tail())\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "food_history_df[[\"accuracy\", \"val_accuracy\"]].plot(ax=axes[0])\n",
        "axes[0].set_title(\"Acurácia Food-101\")\n",
        "axes[0].set_xlabel(\"épocas\")\n",
        "axes[0].set_ylabel(\"acurácia\")\n",
        "axes[0].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "food_history_df[[\"loss\", \"val_loss\"]].plot(ax=axes[1])\n",
        "axes[1].set_title(\"Loss Food-101\")\n",
        "axes[1].set_xlabel(\"épocas\")\n",
        "axes[1].set_ylabel(\"loss\")\n",
        "axes[1].grid(True, linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_metrics = food_model.evaluate(food_val_ds, return_dict=True, verbose=0)\n",
        "print(val_metrics)\n",
        "\n",
        "val_images, val_labels = next(iter(food_val_ds.take(1)))\n",
        "val_probs = food_model.predict(val_images)\n",
        "val_preds = tf.argmax(val_probs, axis=1)\n",
        "val_true = tf.argmax(val_labels, axis=1)\n",
        "\n",
        "for idx in range(min(5, val_images.shape[0])):\n",
        "    true_label = food_class_names[int(val_true[idx])]\n",
        "    pred_label = food_class_names[int(val_preds[idx])]\n",
        "    confidence = tf.reduce_max(val_probs[idx]).numpy()\n",
        "    print(f\"Imagem {idx}: real={true_label} | previsto={pred_label} ({confidence:.2%})\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(val_images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(f\"{food_class_names[int(val_preds[i])]}\\nreal: {food_class_names[int(val_true[i])]}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fine-tuning opcional\n",
        "\n",
        "Descomente o bloco abaixo caso queira liberar as últimas camadas do EfficientNet para ajuste fino depois que o cabeçalho estiver estável. Recomendo reduzir bastante a `learning_rate` antes de rodar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# base_model = food_model.get_layer(\"efficientnetb0\")\n",
        "# for layer in base_model.layers[-30:]:\n",
        "#     layer.trainable = True\n",
        "# food_model.compile(\n",
        "#     optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE * 0.1),\n",
        "#     loss=\"categorical_crossentropy\",\n",
        "#     metrics=[\"accuracy\"],\n",
        "# )\n",
        "# fine_tune_history = food_model.fit(\n",
        "#     food_train_ds,\n",
        "#     validation_data=food_val_ds,\n",
        "#     epochs=5,\n",
        "#     verbose=2,\n",
        "# )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save(MODEL_OUTPUT_DIR / \"food101_class_names.npy\", np.array(food_class_names))\n",
        "print(f\"Classes salvas em {MODEL_OUTPUT_DIR / 'food101_class_names.npy'}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Como levar tudo para o Google Colab\n",
        "\n",
        "1. Comprima a pasta `archive (1)` em `.zip` e faça upload para o Drive. No Colab, use `!unzip` dentro de `/content/drive/MyDrive/pp4_datasets/`.\n",
        "2. Suba `nutrition.csv` para a mesma pasta.\n",
        "3. Abra este notebook no Colab, monte o Drive e ajuste `BASE_DATA_DIR` se usar outro caminho.\n",
        "4. Execute todas as células na ordem. Os modelos e artefatos serão salvos em `BASE_DATA_DIR / modelos_treinados`, facilitando o download posterior (`files.download`).\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
