{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimentos de Deep Learning - Food Image Classification (Local)\n",
        "\n",
        "Este notebook contém experimentos completos para rodar localmente no Jupyter, utilizando o dataset Food-101 do arquivo `archive (1).zip`.\n",
        "\n",
        "## Experimentos incluídos:\n",
        "\n",
        "1. **Extração e exploração do dataset**\n",
        "2. **Preparação e pré-processamento dos dados**\n",
        "3. **Classificação de imagens com CNN simples**\n",
        "4. **Transfer Learning com modelos pré-treinados**\n",
        "5. **Análise de resultados e visualizações**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verificando e instalando dependências...\n",
            "✓ numpy já instalado\n",
            "✓ pandas já instalado\n",
            "Instalando matplotlib...\n",
            "✓ matplotlib instalado com sucesso\n",
            "Instalando seaborn...\n",
            "✓ seaborn instalado com sucesso\n",
            "Instalando pillow...\n",
            "✓ pillow instalado com sucesso\n",
            "Instalando scikit-learn...\n",
            "✓ scikit-learn instalado com sucesso\n",
            "\n",
            "Todas as dependências estão prontas!\n"
          ]
        }
      ],
      "source": [
        "# Instalar dependências necessárias (execute esta célula primeiro se houver erros de importação)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Instala um pacote usando pip\"\"\"\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
        "\n",
        "# Lista de pacotes necessários\n",
        "packages = [\n",
        "    \"numpy\",\n",
        "    \"pandas\", \n",
        "    \"matplotlib\",\n",
        "    \"seaborn\",\n",
        "    \"pillow\",\n",
        "    \"scikit-learn\"\n",
        "]\n",
        "\n",
        "print(\"Verificando e instalando dependências...\")\n",
        "for package in packages:\n",
        "    try:\n",
        "        __import__(package.replace(\"-\", \"_\"))\n",
        "        print(f\"✓ {package} já instalado\")\n",
        "    except ImportError:\n",
        "        print(f\"Instalando {package}...\")\n",
        "        install_package(package)\n",
        "        print(f\"✓ {package} instalado com sucesso\")\n",
        "\n",
        "print(\"\\nTodas as dependências estão prontas!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠ TensorFlow não disponível: No module named 'tensorflow'\n",
            "⚠ Você pode executar as células de exploração de dados, mas não poderá treinar modelos.\n",
            "⚠ Para instalar TensorFlow, execute: pip install tensorflow\n",
            "\n",
            "✓ NumPy version: 2.3.5\n",
            "✓ Pandas version: 2.3.3\n",
            "✓ Matplotlib version: 3.10.7\n",
            "\n",
            "✓ Todas as importações básicas concluídas!\n"
          ]
        }
      ],
      "source": [
        "# Importações necessárias\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Tentar importar TensorFlow (opcional - pode não estar disponível)\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers, optimizers, callbacks\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    TENSORFLOW_AVAILABLE = True\n",
        "    print(f\"✓ TensorFlow version: {tf.__version__}\")\n",
        "    print(f\"✓ GPUs disponíveis: {len(tf.config.list_physical_devices('GPU'))}\")\n",
        "    if tf.config.list_physical_devices('GPU'):\n",
        "        print(\"✓ GPU detectada! Treinamento será acelerado.\")\n",
        "    else:\n",
        "        print(\"ℹ Usando CPU. Treinamento pode ser mais lento.\")\n",
        "except ImportError as e:\n",
        "    TENSORFLOW_AVAILABLE = False\n",
        "    print(f\"⚠ TensorFlow não disponível: {e}\")\n",
        "    print(\"⚠ Você pode executar as células de exploração de dados, mas não poderá treinar modelos.\")\n",
        "    print(\"⚠ Para instalar TensorFlow, execute: pip install tensorflow\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Configurações\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "if TENSORFLOW_AVAILABLE:\n",
        "    tf.random.set_seed(SEED)\n",
        "\n",
        "print(f\"\\n✓ NumPy version: {np.__version__}\")\n",
        "print(f\"✓ Pandas version: {pd.__version__}\")\n",
        "print(f\"✓ Matplotlib version: {plt.matplotlib.__version__}\")\n",
        "print(\"\\n✓ Todas as importações básicas concluídas!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Extração e Configuração do Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraindo arquivo zip...\n",
            "Extração concluída!\n",
            "\n",
            "Diretório base: c:\\Users\\Zion & Mariana\\Desktop\\Atvidades\\pp4\n",
            "Pasta de imagens existe: False\n",
            "Pasta de metadados existe: True\n"
          ]
        }
      ],
      "source": [
        "# Configuração de caminhos\n",
        "BASE_DIR = Path.cwd()\n",
        "ZIP_FILE = BASE_DIR / \"archive (1).zip\"\n",
        "ARCHIVE_DIR = BASE_DIR / \"archive (1)\"\n",
        "IMAGES_DIR = ARCHIVE_DIR / \"images\"\n",
        "META_DIR = ARCHIVE_DIR / \"meta\" / \"meta\"\n",
        "\n",
        "# Extrair o zip se necessário\n",
        "if ZIP_FILE.exists() and not IMAGES_DIR.exists():\n",
        "    print(\"Extraindo arquivo zip...\")\n",
        "    with zipfile.ZipFile(ZIP_FILE, 'r') as zip_ref:\n",
        "        zip_ref.extractall(BASE_DIR)\n",
        "    print(\"Extração concluída!\")\n",
        "elif IMAGES_DIR.exists():\n",
        "    print(\"Dataset já extraído!\")\n",
        "else:\n",
        "    print(f\"⚠️ Arquivo {ZIP_FILE} não encontrado!\")\n",
        "\n",
        "# Verificar estrutura\n",
        "print(f\"\\nDiretório base: {BASE_DIR}\")\n",
        "print(f\"Pasta de imagens existe: {IMAGES_DIR.exists()}\")\n",
        "print(f\"Pasta de metadados existe: {META_DIR.exists()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploração do Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de classes: 101\n",
            "\n",
            "Primeiras 10 classes: ['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito']\n",
            "⚠️ Pasta de imagens não encontrada!\n"
          ]
        }
      ],
      "source": [
        "# Carregar classes\n",
        "if META_DIR.exists():\n",
        "    classes_file = META_DIR / \"classes.txt\"\n",
        "    if classes_file.exists():\n",
        "        with open(classes_file, 'r') as f:\n",
        "            classes = [line.strip() for line in f.readlines()]\n",
        "        print(f\"Total de classes: {len(classes)}\")\n",
        "        print(f\"\\nPrimeiras 10 classes: {classes[:10]}\")\n",
        "    else:\n",
        "        print(\"Arquivo classes.txt não encontrado!\")\n",
        "        classes = []\n",
        "else:\n",
        "    classes = []\n",
        "\n",
        "# Explorar estrutura de imagens\n",
        "if IMAGES_DIR.exists():\n",
        "    class_dirs = [d for d in IMAGES_DIR.iterdir() if d.is_dir()]\n",
        "    print(f\"\\nTotal de pastas de classes encontradas: {len(class_dirs)}\")\n",
        "    \n",
        "    # Contar imagens por classe\n",
        "    class_counts = {}\n",
        "    for class_dir in class_dirs[:10]:  # Primeiras 10 classes\n",
        "        images = list(class_dir.glob(\"*.jpg\"))\n",
        "        class_counts[class_dir.name] = len(images)\n",
        "    \n",
        "    print(\"\\nNúmero de imagens por classe (primeiras 10):\")\n",
        "    for cls, count in class_counts.items():\n",
        "        print(f\"  {cls}: {count} imagens\")\n",
        "    \n",
        "    # Total de imagens\n",
        "    total_images = sum(len(list(d.glob(\"*.jpg\"))) for d in class_dirs)\n",
        "    print(f\"\\nTotal de imagens no dataset: {total_images}\")\n",
        "else:\n",
        "    print(\"⚠️ Pasta de imagens não encontrada!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar algumas imagens de exemplo\n",
        "if IMAGES_DIR.exists():\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    class_dirs = [d for d in IMAGES_DIR.iterdir() if d.is_dir()][:5]\n",
        "    idx = 0\n",
        "    \n",
        "    for class_dir in class_dirs:\n",
        "        images = list(class_dir.glob(\"*.jpg\"))[:2]\n",
        "        for img_path in images:\n",
        "            if idx < 10:\n",
        "                img = Image.open(img_path)\n",
        "                axes[idx].imshow(img)\n",
        "                axes[idx].set_title(f\"{class_dir.name}\\n{img.size}\")\n",
        "                axes[idx].axis('off')\n",
        "                idx += 1\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Preparação dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando 10 classes para treinamento:\n",
            "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito']\n"
          ]
        }
      ],
      "source": [
        "# Configurações para preparação dos dados\n",
        "IMG_SIZE = 224  # Tamanho padrão para modelos pré-treinados\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = len(classes) if classes else 101\n",
        "\n",
        "# Para experimentos mais rápidos, vamos usar um subconjunto das classes\n",
        "# Altere este valor para usar mais ou menos classes\n",
        "SUBSET_CLASSES = 10  # Usar apenas 10 classes para treinamento mais rápido\n",
        "\n",
        "if classes:\n",
        "    selected_classes = classes[:SUBSET_CLASSES]\n",
        "    print(f\"Usando {len(selected_classes)} classes para treinamento:\")\n",
        "    print(selected_classes)\n",
        "else:\n",
        "    selected_classes = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Não foi possível criar os geradores de dados!\n"
          ]
        }
      ],
      "source": [
        "# Função para carregar dados usando ImageDataGenerator\n",
        "if TENSORFLOW_AVAILABLE:\n",
        "    def create_data_generators(images_dir, selected_classes, img_size=224, batch_size=32, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Cria geradores de dados para treino e validação\n",
        "        \"\"\"\n",
        "        # Data augmentation para treino\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            zoom_range=0.2,\n",
        "            validation_split=validation_split\n",
        "        )\n",
        "        \n",
        "        # Apenas normalização para validação\n",
        "        val_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            validation_split=validation_split\n",
        "        )\n",
        "        \n",
        "        # Criar geradores\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            images_dir,\n",
        "            target_size=(img_size, img_size),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='training',\n",
        "            classes=selected_classes,\n",
        "            seed=SEED\n",
        "        )\n",
        "        \n",
        "        val_generator = val_datagen.flow_from_directory(\n",
        "            images_dir,\n",
        "            target_size=(img_size, img_size),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='validation',\n",
        "            classes=selected_classes,\n",
        "            seed=SEED\n",
        "        )\n",
        "        \n",
        "        return train_generator, val_generator\n",
        "\n",
        "    # Criar geradores se TensorFlow estiver disponível\n",
        "    if IMAGES_DIR.exists() and selected_classes:\n",
        "        try:\n",
        "            train_gen, val_gen = create_data_generators(\n",
        "                IMAGES_DIR, \n",
        "                selected_classes, \n",
        "                IMG_SIZE, \n",
        "                BATCH_SIZE\n",
        "            )\n",
        "            \n",
        "            print(f\"✓ Classes encontradas: {list(train_gen.class_indices.keys())}\")\n",
        "            print(f\"✓ Número de amostras de treino: {train_gen.samples}\")\n",
        "            print(f\"✓ Número de amostras de validação: {val_gen.samples}\")\n",
        "            print(f\"✓ Número de classes: {train_gen.num_classes}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Erro ao criar geradores: {e}\")\n",
        "            train_gen = None\n",
        "            val_gen = None\n",
        "    else:\n",
        "        print(\"⚠️ Não foi possível criar os geradores de dados!\")\n",
        "        print(f\"   - IMAGES_DIR existe: {IMAGES_DIR.exists()}\")\n",
        "        print(f\"   - Classes selecionadas: {len(selected_classes) if selected_classes else 0}\")\n",
        "        train_gen = None\n",
        "        val_gen = None\n",
        "else:\n",
        "    print(\"⚠️ TensorFlow não está disponível!\")\n",
        "    print(\"⚠️ Não é possível criar geradores de dados sem TensorFlow.\")\n",
        "    print(\"⚠️ Você pode executar as células de exploração de dados, mas não poderá treinar modelos.\")\n",
        "    train_gen = None\n",
        "    val_gen = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Modelo CNN Simples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_simple_cnn(input_shape=(224, 224, 3), num_classes=10):\n",
        "    \"\"\"\n",
        "    Cria uma CNN simples para classificação de imagens\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        # Primeira camada convolucional\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "        \n",
        "        # Segunda camada convolucional\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "        \n",
        "        # Terceira camada convolucional\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "        \n",
        "        # Quarta camada convolucional\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(2, 2),\n",
        "        \n",
        "        # Flatten e camadas densas\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    return model\n",
        "\n",
        "if 'train_gen' in locals():\n",
        "    num_classes = train_gen.num_classes\n",
        "    simple_model = create_simple_cnn((IMG_SIZE, IMG_SIZE, 3), num_classes)\n",
        "    \n",
        "    simple_model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    print(\"Arquitetura do modelo CNN simples:\")\n",
        "    simple_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Modelo ou geradores não foram criados!\n"
          ]
        }
      ],
      "source": [
        "# Treinar modelo CNN simples\n",
        "if 'simple_model' in locals() and 'train_gen' in locals():\n",
        "    print(\"Iniciando treinamento do modelo CNN simples...\")\n",
        "    print(\"⚠️ Este processo pode demorar. Ajuste EPOCHS se necessário.\")\n",
        "    \n",
        "    EPOCHS = 10  # Reduza este número para treinamento mais rápido\n",
        "    \n",
        "    # Callbacks\n",
        "    early_stopping = callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    \n",
        "    reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=2,\n",
        "        min_lr=0.0001\n",
        "    )\n",
        "    \n",
        "    history_simple = simple_model.fit(\n",
        "        train_gen,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    print(\"\\n✅ Treinamento concluído!\")\n",
        "else:\n",
        "    print(\"⚠️ Modelo ou geradores não foram criados!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar histórico de treinamento - CNN Simples\n",
        "if 'history_simple' in locals():\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    \n",
        "    # Accuracy\n",
        "    axes[0].plot(history_simple.history['accuracy'], label='Treino')\n",
        "    axes[0].plot(history_simple.history['val_accuracy'], label='Validação')\n",
        "    axes[0].set_title('Acurácia - CNN Simples')\n",
        "    axes[0].set_xlabel('Época')\n",
        "    axes[0].set_ylabel('Acurácia')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # Loss\n",
        "    axes[1].plot(history_simple.history['loss'], label='Treino')\n",
        "    axes[1].plot(history_simple.history['val_loss'], label='Validação')\n",
        "    axes[1].set_title('Loss - CNN Simples')\n",
        "    axes[1].set_xlabel('Época')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Avaliar no conjunto de validação\n",
        "    val_loss, val_acc = simple_model.evaluate(val_gen, verbose=0)\n",
        "    print(f\"\\nAcurácia final na validação: {val_acc:.4f}\")\n",
        "    print(f\"Loss final na validação: {val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Transfer Learning com MobileNetV2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_transfer_learning_model(input_shape=(224, 224, 3), num_classes=10):\n",
        "    \"\"\"\n",
        "    Cria um modelo usando Transfer Learning com MobileNetV2\n",
        "    \"\"\"\n",
        "    # Carregar MobileNetV2 pré-treinado (sem a camada de classificação)\n",
        "    base_model = keras.applications.MobileNetV2(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    # Congelar camadas base (opcional - pode descongelar para fine-tuning)\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # Adicionar camadas de classificação\n",
        "    model = keras.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    return model\n",
        "\n",
        "if 'train_gen' in locals():\n",
        "    num_classes = train_gen.num_classes\n",
        "    transfer_model = create_transfer_learning_model((IMG_SIZE, IMG_SIZE, 3), num_classes)\n",
        "    \n",
        "    transfer_model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    print(\"Arquitetura do modelo com Transfer Learning:\")\n",
        "    transfer_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Modelo ou geradores não foram criados!\n"
          ]
        }
      ],
      "source": [
        "# Treinar modelo com Transfer Learning\n",
        "if 'transfer_model' in locals() and 'train_gen' in locals():\n",
        "    print(\"Iniciando treinamento do modelo com Transfer Learning...\")\n",
        "    print(\"⚠️ Este processo pode demorar. Ajuste EPOCHS se necessário.\")\n",
        "    \n",
        "    EPOCHS_TL = 10  # Reduza este número para treinamento mais rápido\n",
        "    \n",
        "    # Callbacks\n",
        "    early_stopping_tl = callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=3,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    \n",
        "    reduce_lr_tl = callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=2,\n",
        "        min_lr=0.00001\n",
        "    )\n",
        "    \n",
        "    history_transfer = transfer_model.fit(\n",
        "        train_gen,\n",
        "        epochs=EPOCHS_TL,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=[early_stopping_tl, reduce_lr_tl],\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    print(\"\\n✅ Treinamento concluído!\")\n",
        "else:\n",
        "    print(\"⚠️ Modelo ou geradores não foram criados!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar histórico de treinamento - Transfer Learning\n",
        "if 'history_transfer' in locals():\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    \n",
        "    # Accuracy\n",
        "    axes[0].plot(history_transfer.history['accuracy'], label='Treino')\n",
        "    axes[0].plot(history_transfer.history['val_accuracy'], label='Validação')\n",
        "    axes[0].set_title('Acurácia - Transfer Learning')\n",
        "    axes[0].set_xlabel('Época')\n",
        "    axes[0].set_ylabel('Acurácia')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # Loss\n",
        "    axes[1].plot(history_transfer.history['loss'], label='Treino')\n",
        "    axes[1].plot(history_transfer.history['val_loss'], label='Validação')\n",
        "    axes[1].set_title('Loss - Transfer Learning')\n",
        "    axes[1].set_xlabel('Época')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Avaliar no conjunto de validação\n",
        "    val_loss_tl, val_acc_tl = transfer_model.evaluate(val_gen, verbose=0)\n",
        "    print(f\"\\nAcurácia final na validação: {val_acc_tl:.4f}\")\n",
        "    print(f\"Loss final na validação: {val_loss_tl:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Comparação de Modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar performance dos modelos\n",
        "if 'history_simple' in locals() and 'history_transfer' in locals():\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Comparar accuracy\n",
        "    axes[0].plot(history_simple.history['val_accuracy'], label='CNN Simples', marker='o')\n",
        "    axes[0].plot(history_transfer.history['val_accuracy'], label='Transfer Learning', marker='s')\n",
        "    axes[0].set_title('Comparação de Acurácia na Validação')\n",
        "    axes[0].set_xlabel('Época')\n",
        "    axes[0].set_ylabel('Acurácia')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # Comparar loss\n",
        "    axes[1].plot(history_simple.history['val_loss'], label='CNN Simples', marker='o')\n",
        "    axes[1].plot(history_transfer.history['val_loss'], label='Transfer Learning', marker='s')\n",
        "    axes[1].set_title('Comparação de Loss na Validação')\n",
        "    axes[1].set_xlabel('Época')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Resumo numérico\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"RESUMO DE PERFORMANCE\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nCNN Simples:\")\n",
        "    print(f\"  Acurácia final: {max(history_simple.history['val_accuracy']):.4f}\")\n",
        "    print(f\"  Loss final: {min(history_simple.history['val_loss']):.4f}\")\n",
        "    print(f\"\\nTransfer Learning:\")\n",
        "    print(f\"  Acurácia final: {max(history_transfer.history['val_accuracy']):.4f}\")\n",
        "    print(f\"  Loss final: {min(history_transfer.history['val_loss']):.4f}\")\n",
        "    print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Teste com Imagens de Exemplo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Modelo ou geradores não disponíveis para teste!\n"
          ]
        }
      ],
      "source": [
        "# Função para fazer predições em imagens\n",
        "def predict_image(model, img_path, class_names, img_size=224):\n",
        "    \"\"\"\n",
        "    Faz predição em uma única imagem\n",
        "    \"\"\"\n",
        "    img = Image.open(img_path)\n",
        "    img = img.resize((img_size, img_size))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    \n",
        "    predictions = model.predict(img_array, verbose=0)\n",
        "    predicted_class_idx = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class_idx]\n",
        "    \n",
        "    return img, class_names[predicted_class_idx], confidence, predictions[0]\n",
        "\n",
        "# Testar com algumas imagens do conjunto de validação\n",
        "if 'transfer_model' in locals() and 'val_gen' in locals() and IMAGES_DIR.exists():\n",
        "    # Pegar algumas imagens aleatórias\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    class_names = list(val_gen.class_indices.keys())\n",
        "    \n",
        "    # Pegar uma imagem de cada classe disponível\n",
        "    for idx, class_name in enumerate(class_names[:6]):\n",
        "        class_dir = IMAGES_DIR / class_name\n",
        "        if class_dir.exists():\n",
        "            images = list(class_dir.glob(\"*.jpg\"))\n",
        "            if images:\n",
        "                img_path = images[0]\n",
        "                img, pred_class, confidence, all_preds = predict_image(\n",
        "                    transfer_model, img_path, class_names, IMG_SIZE\n",
        "                )\n",
        "                \n",
        "                axes[idx].imshow(img)\n",
        "                axes[idx].set_title(f\"Real: {class_name}\\nPredito: {pred_class}\\nConfiança: {confidence:.2%}\")\n",
        "                axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"⚠️ Modelo ou geradores não disponíveis para teste!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Salvar Modelos (Opcional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Todos os modelos salvos em: c:\\Users\\Zion & Mariana\\Desktop\\Atvidades\\pp4\\modelos_salvos\n"
          ]
        }
      ],
      "source": [
        "# Salvar modelos treinados\n",
        "MODELS_DIR = BASE_DIR / \"modelos_salvos\"\n",
        "MODELS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "if 'simple_model' in locals():\n",
        "    simple_model_path = MODELS_DIR / \"cnn_simples_food101.h5\"\n",
        "    simple_model.save(simple_model_path)\n",
        "    print(f\"✅ Modelo CNN simples salvo em: {simple_model_path}\")\n",
        "\n",
        "if 'transfer_model' in locals():\n",
        "    transfer_model_path = MODELS_DIR / \"transfer_learning_food101.h5\"\n",
        "    transfer_model.save(transfer_model_path)\n",
        "    print(f\"✅ Modelo Transfer Learning salvo em: {transfer_model_path}\")\n",
        "\n",
        "print(f\"\\nTodos os modelos salvos em: {MODELS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notas Finais\n",
        "\n",
        "### Dicas para melhorar os resultados:\n",
        "\n",
        "1. **Aumentar número de classes**: Altere `SUBSET_CLASSES` para usar mais classes\n",
        "2. **Aumentar épocas**: Aumente `EPOCHS` e `EPOCHS_TL` para treinamento mais longo\n",
        "3. **Fine-tuning**: Descongele algumas camadas do modelo base para fine-tuning\n",
        "4. **Data Augmentation**: Ajuste os parâmetros de augmentation para mais diversidade\n",
        "5. **Tamanho da imagem**: Experimente diferentes tamanhos (128, 256, etc.)\n",
        "6. **Batch size**: Ajuste conforme sua memória disponível\n",
        "\n",
        "### Próximos passos:\n",
        "\n",
        "- Experimentar com outros modelos pré-treinados (ResNet, EfficientNet, etc.)\n",
        "- Implementar ensemble de modelos\n",
        "- Adicionar análise de matriz de confusão detalhada\n",
        "- Implementar grad-CAM para visualização de atenção\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
